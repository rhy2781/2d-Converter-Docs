"use strict";(self.webpackChunk_2_d_converter_docs=self.webpackChunk_2_d_converter_docs||[]).push([[8575],{1555:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>d,contentTitle:()=>i,default:()=>l,frontMatter:()=>o,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"Sketch-A-Shape/stage_2","title":"Stage II - Prior Model","description":"The purpose of this stage is to take the encoder section of a large pre-trained model and translate the semantic","source":"@site/docs/Sketch-A-Shape/stage_2.md","sourceDirName":"Sketch-A-Shape","slug":"/Sketch-A-Shape/stage_2","permalink":"/2d-Converter-Docs/docs/Sketch-A-Shape/stage_2","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Sketch-A-Shape/stage_2.md","tags":[],"version":"current","frontMatter":{},"sidebar":"docSidebar","previous":{"title":"Stage I Auto-Encoder","permalink":"/2d-Converter-Docs/docs/Sketch-A-Shape/stage_1"},"next":{"title":"temporary placeholder?","permalink":"/2d-Converter-Docs/docs/intro"}}');var n=r(4848),s=r(8453);const o={},i="Stage II - Prior Model",d={},c=[{value:"Dataset",id:"dataset",level:2},{value:"Structure",id:"structure",level:2},{value:"Large Pre-Trained Model",id:"large-pre-trained-model",level:3},{value:"Mapping Network",id:"mapping-network",level:3},{value:"Self-Attention Network",id:"self-attention-network",level:3},{value:"MaskGIT Bi-Directional Transformer",id:"maskgit-bi-directional-transformer",level:3}];function h(e){const t={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"stage-ii---prior-model",children:"Stage II - Prior Model"})}),"\n",(0,n.jsx)(t.p,{children:"The purpose of this stage is to take the encoder section of a large pre-trained model and translate the semantic\r\nfeatures into compressed shape embeddings that are consistent wih the Auto-Encoder that is trained in Stage I."}),"\n",(0,n.jsx)(t.h2,{id:"dataset",children:"Dataset"}),"\n",(0,n.jsxs)(t.p,{children:["For this model, we render the objects from the ",(0,n.jsx)(t.a,{href:"https://shapenet.org",children:"ShapeNet Dataset"})," in different angles and create\r\nsynthetic images. This allows us to have a matching shape embedding and correlating image form which extra layers can be\r\nadded so that the semantic features from the large pre-trained model are correctly translated into our shape embeddings."]}),"\n",(0,n.jsx)(t.h2,{id:"structure",children:"Structure"}),"\n",(0,n.jsx)(t.h3,{id:"large-pre-trained-model",children:"Large Pre-Trained Model"}),"\n",(0,n.jsxs)(t.p,{children:["The paper leverages the ",(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2103.00020",children:"CLIP model"})," trained by ",(0,n.jsx)(t.a,{href:"https://github.com/openai/CLIP",children:"OpenAI"}),",\r\nand the implementation of CLIP was taken from this ",(0,n.jsx)(t.a,{href:"https://github.com/mlfoundations/open_clip",children:"GitHub"})]}),"\n",(0,n.jsx)(t.h3,{id:"mapping-network",children:"Mapping Network"}),"\n",(0,n.jsx)(t.h3,{id:"self-attention-network",children:"Self-Attention Network"}),"\n",(0,n.jsx)(t.h3,{id:"maskgit-bi-directional-transformer",children:"MaskGIT Bi-Directional Transformer"})]})}function l(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(h,{...e})}):h(e)}},8453:(e,t,r)=>{r.d(t,{R:()=>o,x:()=>i});var a=r(6540);const n={},s=a.createContext(n);function o(e){const t=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:o(e.components),a.createElement(s.Provider,{value:t},e.children)}}}]);